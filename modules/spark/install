#!/bin/sh

 SCRIPT_DIR=$(dirname $0)
 ADDED_DIR=${SCRIPT_DIR}/added

# If there is a zero-length spark tarball, find the verison in the
# name and download from Apache
fullname=$(find $ARTIFACTS_DIR -name spark-[0-9.]*\.tgz)
/bin/sh -x $SCRIPT_DIR/check_for_download $fullname

# unpack the spark tools
{
    cd /tmp/artifacts
    tar xzf spark-*-bin-hadoop*.tgz
    mv spark-*-bin-hadoop*/ /opt
    ln -s /opt/spark-*-bin-hadoop* "/opt/spark"
}

mv $ADDED_DIR/entrypoint /
chmod +x /entrypoint

mv $ADDED_DIR/launch.sh $SPARK_HOME/bin/
chmod +x $SPARK_HOME/bin/launch.sh

mv $ADDED_DIR/*.properties $SPARK_HOME/conf/
mv $ADDED_DIR/*.conf $SPARK_HOME/conf/
mv $ADDED_DIR/*.yaml $SPARK_HOME/conf/

# SPARK_WORKER_DIR defaults to SPARK_HOME/work and is created on
# Worker startup if it does not exist. instead of making SPARK_HOME
 # world writable, create SPARK_HOME/work.
mkdir $SPARK_HOME/work
chmod a+rwx $SPARK_HOME/work

chmod -R a+rwX $SPARK_HOME
chmod a+rw /etc/passwd

TINI_VERSION=v0.16.1
wget -q https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini -P /tmp
wget -q https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini.asc -P /tmp
cd /tmp
gpg --keyserver ha.pool.sks-keyservers.net --recv-keys 0527A9B7 && gpg --verify /tmp/tini.asc
mv /tmp/tini /usr/local/bin/tini
chmod +x /usr/local/bin/tini
