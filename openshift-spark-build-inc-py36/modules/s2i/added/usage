#!/bin/bash
if [ -f "$SPARK_HOME"/bin/spark-submit ]; then
    echo full image usage would go here
    exit 0
fi


cat <<EOF
This is an incomplete openshift-spark image. It contains scripts for running an
Apache Spark master or worker but is missing an actual Spark distribution.

To produce a final image, a source-to-image build must be performed which takes
a Spark distribution as input. This can be done in OpenShift or locally using
the s2i tool if it's installed.

Build inputs:
-------------

The OpenShift method can take either local files or a URL as build input.
For the s2i method, local files are required. Here is an example which
downloads an Apache Spark distribution to a local 'build_input' directory
(including the md5 file is optional).

$ mkdir build_input
$ wget https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz -O build_input/spark-2.3.0-bin-hadoop2.7.tgz
$ wget https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz.md5 -O build_input/spark-2.3.0-bin-hadoop2.7.tgz.md5

Completing the image with OpenShift:
------------------------------------

Run a binary build specifying the spark distribution, for example:

$ oc new-build --name=openshift-spark --docker-image=radanalyticsio/openshift-spark-inc --binary
$ oc start-build openshift-spark --from-file=https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz

This will write the completed image to an imagestream called 'openshift-spark'
in the current project. Note that the value of --from-file can also be a local
directory (see Build Inputs above).

Completing the image with the s2i tool:
---------------------------------------

s2i build build_input radanalyticsio/openshift-spark-inc openshift-spark

This will build a local image named 'openshift-spark:latest' which can
then be uploaded to an image repository.
EOF
